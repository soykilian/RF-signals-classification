{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## In this notebook we attempt to train a ResNet structure\n",
    " - Inputs : Time sequences with 1024 samples\n",
    " - Label: 23 possible modulations (M_FSK, LFM, M_PSK, ...)\n",
    "\n",
    "More information on the residual stack from ResNet [here](https://towardsdatascience.com/intuition-behind-residual-neural-networks-fa5d2996b2c7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Add, Conv1D,Convolution2D, Bidirectional, LSTM, GRU, AlphaDropout, MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import sklearn, json\n",
    "import scipy.io as io\n",
    "from typing import Any, Dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from includes.clr_callback import *\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = '/Users/mariavictoriadacostarivas/Documents/GMR/'\n",
    "dataset_path = path + 'Dataset/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126500, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(dataset_path +'X_train.mat', 'r') as f:\n",
    "    X_train = np.array(f['X_train']).T\n",
    "print(X_train.shape)\n",
    "with h5py.File(dataset_path +'X_test.mat', 'r') as f:\n",
    "    X_test = np.array(f['X_test']).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25300, 6)\n",
      "(126500, 6)\n"
     ]
    }
   ],
   "source": [
    "lbl_train = io.loadmat(dataset_path + 'lbl_train.mat')['lbl_train']\n",
    "lbl_test = io.loadmat(dataset_path + 'lbl_test.mat')['lbl_test']\n",
    "print(lbl_test.shape)\n",
    "print(lbl_train.shape)\n",
    "Y_train = io.loadmat(dataset_path + 'Y_train.mat')\n",
    "Y_train = Y_train['Y_train']\n",
    "Y_test = io.loadmat(dataset_path + 'Y_test.mat')\n",
    "Y_test = Y_test['Y_test']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "classes = ['LFM', '2FSK', '4FSK', '8FSK', 'Costas', '2PSK', '4PSK', '8PSK', 'Barker', 'Huffman', 'Frank', 'P1', 'P2',\n",
    "           'P3', 'P4', 'Px', 'Zadoff-Chu', 'T1', 'T2', 'T3', 'T4', 'NM', 'ruido']\n",
    "I_x = X_train[:, :, 0]\n",
    "Q_x = X_train[:, :, 1]\n",
    "X_train[:, :, 1] = np.arctan(Q_x, I_x) / np.pi\n",
    "X_train[:, :, 0] = np.abs(I_x + 1j * Q_x)\n",
    "I_t = X_test[:, :, 0]\n",
    "Q_t = X_test[:, :, 1]\n",
    "X_test[:, :, 0] = np.arctan(Q_t, I_t) / np.pi\n",
    "X_test[:, :, 1] = np.abs(I_t + 1j * Q_t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "X_train, Y_train, lbl_train = sklearn.utils.shuffle(X_train[:], Y_train[:], lbl_train[:], random_state=2022)\n",
    "X_test, Y_test, lbl_test = sklearn.utils.shuffle(X_test[:], Y_test[:], lbl_test[:], random_state=2022)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We have to create the structure of a residual stack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def res_stack(x, f):\n",
    "    \"\"\"\n",
    "    x : input vector\n",
    "    f : output shape\n",
    "    \"\"\"\n",
    "    if x.shape[1] != f:\n",
    "        x = Conv1D(f, 1, strides=1, padding='same', data_format='channels_last')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    x_shortcut = x\n",
    "    x = Conv1D(f, 5, strides=1, padding=\"same\", data_format='channels_last')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(f, 5, strides=1, padding=\"same\", data_format='channels_last')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \"\"\"Now we add the skip connection\"\"\"\n",
    "    if x.shape[1] == x_shortcut.shape[1]:\n",
    "        x = Add()([x, x_shortcut])\n",
    "    else:\n",
    "        raise Exception(\"Skip function not implemented\")\n",
    "    \"\"\"After the addition the relu function is applied\"\"\"\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size=2, strides=None, padding='valid', data_format='channels_last')(x)\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def ResNet(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    x = res_stack(X_input, 32)\n",
    "    x = res_stack(x, 32)\n",
    "    x = res_stack(x, 32)\n",
    "    x = res_stack(x, 32)\n",
    "    x = res_stack(x, 32)\n",
    "    x = res_stack(x, 32)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='selu')(x)\n",
    "    x = AlphaDropout(0.6)(x)\n",
    "    x = Dense(128, activation='selu')(x)\n",
    "    x = AlphaDropout(0.6)(x)\n",
    "    x = Dense(128, activation='softmax')(x)\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = x)\n",
    "    model.summary()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1024, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1024, 32)     96          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1024, 32)     128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1024, 32)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1024, 32)     5152        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024, 32)     128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1024, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1024, 32)     5152        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1024, 32)     128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1024, 32)     0           batch_normalization_2[0][0]      \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1024, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 512, 32)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 512, 32)      1056        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 512, 32)      128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 512, 32)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 512, 32)      5152        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 512, 32)      128         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 512, 32)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 512, 32)      5152        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512, 32)      128         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 512, 32)      0           batch_normalization_5[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 512, 32)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 256, 32)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 256, 32)      1056        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 32)      128         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 32)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 256, 32)      5152        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 32)      128         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256, 32)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 256, 32)      5152        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256, 32)      128         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 32)      0           batch_normalization_8[0][0]      \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 256, 32)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 128, 32)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 128, 32)      1056        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 32)      128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 32)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 128, 32)      5152        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 32)      128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 32)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 128, 32)      5152        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128, 32)      128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 32)      0           batch_normalization_11[0][0]     \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 32)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 64, 32)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 64, 32)       1056        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 32)       128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 32)       0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 64, 32)       5152        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 32)       128         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 32)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 64, 32)       5152        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 32)       128         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 32)       0           batch_normalization_14[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 32)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 32, 32)       0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 32, 32)       5152        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32)       128         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32)       0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 32, 32)       5152        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32)       128         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32)       0           batch_normalization_16[0][0]     \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32)       0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 16, 32)       0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          65664       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout (AlphaDropout)    (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       alpha_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_1 (AlphaDropout)  (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       alpha_dropout_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 167,008\n",
      "Trainable params: 165,920\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(X_train.shape[1:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "output_path = path + 'Results/models'\n",
    "clr_triangular = CyclicLR(mode='triangular', base_lr=1e-7, max_lr=1e-3, step_size= 4 * (X_train.shape[0] // 1200))\n",
    "c=[clr_triangular,ModelCheckpoint(filepath= output_path +'best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "model.compile(optimizer=optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Train = True\n",
    "if Train:\n",
    "    history = model.fit(X_train, Y_train, epochs = 200, batch_size = 150, callbacks = c, validation_data=(X_test, Y_test))\n",
    "    with open(output_path +'history_rnn.json', 'w') as f:\n",
    "        json.dump(history.history, f)\n",
    "    model_json = model.to_json()\n",
    "    with open(output_path +'model_rnn.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "else:\n",
    "    model.load_weights(output_path +'best_model.h5')\n",
    "    with open(output_path +'history_rnn.json', 'r') as f:\n",
    "        history = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['test', 'val'])\n",
    "plt.show()\n",
    "plt.savefig(path+ '\\graphs\\model_loss.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getConfusionMatrixPlot(true_labels, predicted_labels,title):\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "    cm = np.round(cm_norm,2)\n",
    "    print(cm)\n",
    "\n",
    "    # create figure\n",
    "    width = 18\n",
    "    height = width / 1.618\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    plt.clf()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(1)\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "    res = ax.imshow(cm, cmap=plt.cm.binary,\n",
    "                    interpolation='nearest', vmin=0, vmax=1)\n",
    "\n",
    "    # add color bar\n",
    "    plt.colorbar(res)\n",
    "\n",
    "    # annotate confusion entries\n",
    "    width = len(cm)\n",
    "    height = len(cm[0])\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(cm[x][y]), xy=(y, x), horizontalalignment='center',\n",
    "                        verticalalignment='center', color=getFontColor(cm[x][y]))\n",
    "\n",
    "    # add genres as ticks\n",
    "    alphabet = classes\n",
    "    plt.xticks(range(width), alphabet[:width], rotation=30)\n",
    "    plt.yticks(range(height), alphabet[:height])\n",
    "    plt.title(title)\n",
    "    return plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}