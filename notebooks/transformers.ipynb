{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ede5a2e",
   "metadata": {},
   "source": [
    "# Time Series Transformers\n",
    "### We aim to generate a transformer-based structure that generates an embedding from a 1024 time sequences obtained from our database generated with [this matlab code](https://github.com/soykilian/Signal-Generator.git)\n",
    "### Also following [this tutorial](https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e4d0e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 10:45:28.421324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow_addons.layers import MultiHeadAttention\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e07ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(layers.Layer):\n",
    "\n",
    "    def __init__(self, kernel_size : int):\n",
    "        super(Time2Vec, self).__init__(trainable=True,name='Time2VecLayer')\n",
    "        self.k = kernel_size \n",
    "    def build(self, input_shape : int = 1024):\n",
    "        self.wb = self.add_weight(name='wb', shape=(input_shape[1],), initializer='uniform', trainable=True)\n",
    "        self.bb = self.add_weight(name='bb', shape=(input_shape[1],), initializer='uniform', trainable=True)\n",
    "        self.wa = self.add_weight(name='wa',shape=(1, input_shape[1], self.k),initializer='uniform',trainable=True)\n",
    "        self.ba = self.add_weight(name='ba',shape=(1, input_shape[1], self.k),initializer='uniform',trainable=True)\n",
    "        super(Time2Vec, self).build(input_shape)\n",
    "    def call(self, inputs, **kwargs):\n",
    "        bias = self.wb * inputs + self.bb\n",
    "        dp = np.dot(inputs, self.wa) + self.ba\n",
    "        wgts =np.sin(dp)\n",
    "        ret = np.concatenate([K.expand_dims(bias, -1), wgts], -1)\n",
    "        ret = np.reshape(ret, (-1, inputs.shape[1]*(self.k+1)))\n",
    "        return ret\n",
    "    def compute_output_shape(self, input_shape : int):\n",
    "        return (input_shape[0], input_shape[1]*(self.k + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8934d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(keras.Model):\n",
    "    def __init__(self, name : str = 'AttentionBlock',\n",
    "                 num_heads : int =2,\n",
    "                 head_size : int = 128,\n",
    "                ff_dim : int = None,\n",
    "                dropout : int = 0,\n",
    "                **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        if ff_dim is None:\n",
    "            ff_dim = head_size\n",
    "        self.attention = MultiHeadAttention(num_heads=num_heads, head_size=128, dropout=dropout)\n",
    "        self.attention_dropout = keras.layers.Dropout(dropout)\n",
    "        self.attention_norm = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.conv1 = keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation='relu')\n",
    "        self.dropout = keras.layers.Dropout(dropout)\n",
    "        self.norm = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    def build(self, input_shape : int):\n",
    "        self.conv2 = keras.layers.Conv1D(filters=input_shape[-1], kernel_size=1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.attention([inputs])\n",
    "        x = self.attention_dropout(x)\n",
    "        x = self.attention_norm(inputs + x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm(inputs + x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa1bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrunk(keras.Model):\n",
    "    def __init__(self, name='ModelTrunk',\n",
    "                 time2vec_dim=1,\n",
    "                 num_heads=2,\n",
    "                 head_size=128,\n",
    "                 ff_dim=None,\n",
    "                 num_layers=1,\n",
    "                 dropout=0,\n",
    "                **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.time2vec = Time2Vec(kernel_size=time2vec_dim)\n",
    "        if ff_dim is None:\n",
    "            ff_dim = head_size\n",
    "        self.dropout = dropout\n",
    "        self.attention_layers = [AttentionBlock(num_heads=num_heads, head_size=head_size, ff_dim=ff_dim, dropout=dropout) for _ in range (num_layers)]\n",
    "        \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        time_embeddings = keras.layers.TimeDistributed(self.time2vec)(inputs)\n",
    "        x = np.concatenate([inputs,time_embeddings ])\n",
    "        for layer in self.attention_layers :\n",
    "            x = layer(x)\n",
    "        return np.reshape(x, (-1, x.shape[1] * x.shape[2]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f361af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr, warmup_epochs=15, decay_epochs=100, initial_lr=1e-6, base_lr=1e-3, min_lr=5e-5):\n",
    "    if epoch <= warmup_epochs:\n",
    "        pct = epoch / warmup_epochs\n",
    "        return ((base_lr - initial_lr) * pct) + initial_lr\n",
    "\n",
    "    if epoch > warmup_epochs and epoch < warmup_epochs+decay_epochs:\n",
    "        pct = 1 - ((epoch - warmup_epochs) / decay_epochs)\n",
    "        return ((base_lr - min_lr) * pct) + min_lr\n",
    "\n",
    "    return min_lr\n",
    "\n",
    "callbacks = [keras.callbacks.LearningRateScheduler(schedule=lr_scheduler, verbose=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035fada8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 10:45:45.311610: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-26 10:45:45.312682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-26 10:45:45.384091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 10:45:45.384776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2022-08-26 10:45:45.384797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-26 10:45:46.197302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-26 10:45:46.197497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-26 10:45:46.676059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-26 10:45:46.739794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-26 10:45:47.541159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-26 10:45:47.606426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-26 10:45:48.978772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-26 10:45:48.979143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 10:45:48.980988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 10:45:48.982535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-26 10:45:48.983558: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-26 10:45:48.985189: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-26 10:45:48.985455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 10:45:48.987055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2022-08-26 10:45:48.987119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-26 10:45:48.987194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-26 10:45:48.987257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-26 10:45:48.987318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-26 10:45:48.987379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-26 10:45:48.987441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-26 10:45:48.987513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-26 10:45:48.987577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-26 10:45:48.987769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 10:45:48.989542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 10:45:48.991090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-26 10:45:48.994213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-26 10:45:53.809339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-26 10:45:53.809401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-08-26 10:45:53.809418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-08-26 10:45:53.819485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 10:45:53.820263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 10:45:53.821011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 10:45:53.821696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10711 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN V, pci bus id: 0000:01:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "model = ModelTrunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090938d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
